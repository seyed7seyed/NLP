{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   \n",
    "<span style=\"font-family:Arial; font-weight:Bold; font-size:2.3em; color:#00b3e5;\"> NLP Project: Text Classification (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####      \n",
    "<span style=\"font-family:Arial; font-weight:Bold; font-size:1.8em; color:#00b3e5;\"> loading libraries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re, string, unicodedata\n",
    "from   bs4 import BeautifulSoup\n",
    "\n",
    "from   textblob  import TextBlob, Word\n",
    "from   wordcloud import WordCloud, STOPWORDS\n",
    "import spacy\n",
    "\n",
    "from sklearn.svm           import SVC\n",
    "from sklearn.naive_bayes   import MultinomialNB\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model  import LogisticRegression, SGDClassifier\n",
    "from sklearn               import naive_bayes, ensemble, decomposition\n",
    "from sklearn.metrics       import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\EZ-\n",
      "[nltk_data]     Tech\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\EZ-\n",
      "[nltk_data]     Tech\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\EZ-\n",
      "[nltk_data]     Tech\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk   # pip install --upgrade nltk\n",
    "\n",
    "nltk.download('punkt') \n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords') \n",
    "\n",
    "from nltk.corpus          import stopwords\n",
    "from nltk.stem.porter     import PorterStemmer\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.tokenize        import word_tokenize, sent_tokenize\n",
    "from nltk.stem            import LancasterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####      \n",
    "<span style=\"font-family:Arial; font-weight:Bold; font-size:1.8em; color:#00b3e5;\"> loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>sport</td>\n",
       "      <td>dent continues adelaide progress american tayl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>farrell due to make us tv debut actor colin fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>sport</td>\n",
       "      <td>rush future at chester uncertain ian rush s fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           category                                               text\n",
       "95            sport  dent continues adelaide progress american tayl...\n",
       "1490  entertainment  farrell due to make us tv debut actor colin fa...\n",
       "2142          sport  rush future at chester uncertain ian rush s fu..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('bbcText.csv',delimiter=',')\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####      \n",
    "<span style=\"font-family:Arial; font-weight:Bold; font-size:1.8em; color:#00b3e5;\"> EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2225</td>\n",
       "      <td>2225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>2126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>sport</td>\n",
       "      <td>kennedy questions trust of blair lib dem leade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>511</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                               text\n",
       "count      2225                                               2225\n",
       "unique        5                                               2126\n",
       "top       sport  kennedy questions trust of blair lib dem leade...\n",
       "freq        511                                                  2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category    0\n",
       "text        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####      \n",
    "<span style=\"font-family:Arial; font-weight:Bold; font-size:1.8em; color:#00b3e5;\"> NLP Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization of the text\n",
    "tokenizers = ToktokTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the noisy text\n",
    "def noiseremoval_text(text):\n",
    "    soup = BeautifulSoup(text,'html.parser')\n",
    "    text = soup.get_text()\n",
    "    text = re.sub( '\\[[^]]*\\]', '', text )\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function on review column\n",
    "data['text'] = data['text'].apply(noiseremoval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "def stemmer(text):\n",
    "    ps = PorterStemmer()\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function on review column\n",
    "data['text'] = data['text'].apply(stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv futur in the hand of viewer with home theat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss left book alon former worldcom b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tiger wari of farrel gambl leicest say they wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yead face newcastl in fa cup premiership side ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelv raid box offic ocean s twelv the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv futur in the hand of viewer with home theat...\n",
       "1       business  worldcom boss left book alon former worldcom b...\n",
       "2          sport  tiger wari of farrel gambl leicest say they wi...\n",
       "3          sport  yead face newcastl in fa cup premiership side ...\n",
       "4  entertainment  ocean s twelv raid box offic ocean s twelv the..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting English StopWords\n",
    "stopwords  = set( nltk.corpus.stopwords.words('english') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the stopwords\n",
    "def removing_stopwords( text, into_lower_case=False ):\n",
    "    # tokenization of text\n",
    "    tokenizers = ToktokTokenizer()\n",
    "    # setting english stopwords\n",
    "    tokens = tokenizers.tokenize( text )\n",
    "    tokens = [i.strip() for i in tokens]\n",
    "    if into_lower_case:\n",
    "        filtokens = [i for i in tokens if i.lower() not in stopwords]\n",
    "    else:\n",
    "        filtokens = [i for i in tokens if i         not in stopwords]\n",
    "    filtered_text = ' '.join(filtokens)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function on review column\n",
    "data['text'] = data['text'].apply(removing_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>eminem secret gig venu reveal rapper eminem pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>sport</td>\n",
       "      <td>tulu appear caledonian run two-tim olymp 10 00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>business</td>\n",
       "      <td>hous price suffer festiv fall uk hous price fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>sport</td>\n",
       "      <td>sullivan could run world sonia sullivan ha ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>sport</td>\n",
       "      <td>coach ranieri sack valencia claudio ranieri ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           category                                               text\n",
       "655   entertainment  eminem secret gig venu reveal rapper eminem pl...\n",
       "1641          sport  tulu appear caledonian run two-tim olymp 10 00...\n",
       "2128       business  hous price suffer festiv fall uk hous price fe...\n",
       "1013          sport  sullivan could run world sonia sullivan ha ind...\n",
       "81            sport  coach ranieri sack valencia claudio ranieri ha..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####      \n",
    "<span style=\"font-family:Arial; font-weight:Bold; font-size:1.8em; color:#00b3e5;\"> Train-Valid-Test Split (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percents\n",
    "n  = data.shape[0]\n",
    "\n",
    "Train_text = data.text[          :int(.8*n) ]\n",
    "Valid_text = data.text[ int(.8*n):int(.9*n) ]\n",
    "Test_text  = data.text[ int(.9*n):          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####      \n",
    "<span style=\"font-family:Arial; font-weight:Bold; font-size:1.8em; color:#00b3e5;\"> Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling the sentiment data\n",
    "label = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed category data\n",
    "Category_Value = label.fit_transform(data['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2225, 5)\n"
     ]
    }
   ],
   "source": [
    "print( Category_Value.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Category_Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####      \n",
    "<span style=\"font-family:Arial; font-weight:Bold; font-size:1.8em; color:#00b3e5;\"> Train-Valid-Test Split (Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percents\n",
    "n  = data.shape[0]\n",
    "\n",
    "Train_Category = data.category[          :int(.8*n) ]\n",
    "Valid_Category = data.category[ int(.8*n):int(.9*n) ]\n",
    "Test_Category  = data.category[ int(.9*n):          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2058    entertainment\n",
       "2094             tech\n",
       "2019    entertainment\n",
       "Name: category, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Category.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####      \n",
    "<span style=\"font-family:Arial; font-weight:Bold; font-size:1.8em; color:#00b3e5;\"> Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count vectorizer for bag of words\n",
    "cv=CountVectorizer( min_df=0, max_df=1, binary=False, ngram_range=(1,3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed Data\n",
    "CV_Train = cv.fit_transform( Train_text )\n",
    "CV_Valid = cv.transform(     Valid_text )\n",
    "CV_Test  = cv.transform(     Test_text  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW CV_Train: (1780, 570256)\n",
      "BOW CV_Valid: (222, 570256)\n",
      "BOW CV_Test:  (223, 570256)\n"
     ]
    }
   ],
   "source": [
    "print('BOW CV_Train:', CV_Train.shape)\n",
    "print('BOW CV_Valid:', CV_Valid.shape)\n",
    "print('BOW CV_Test: ', CV_Test.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####      \n",
    "<span style=\"font-family:Arial; font-weight:Bold; font-size:1.8em; color:#00b3e5;\"> TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vectorizer  \n",
    "tf = TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed Data\n",
    "TF_Train = tf.fit_transform( Train_text )\n",
    "TF_Valid = tf.transform(     Valid_text )\n",
    "TF_Test  = tf.transform(     Test_text  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW TF_Train: (1780, 570256)\n",
      "BOW TF_Valid: (222, 570256)\n",
      "BOW TF_Test:  (223, 570256)\n"
     ]
    }
   ],
   "source": [
    "print('BOW TF_Train:', TF_Train.shape)\n",
    "print('BOW TF_Valid:', TF_Valid.shape)\n",
    "print('BOW TF_Test: ', TF_Test.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####      \n",
    "<span style=\"font-family:Arial; font-weight:Bold; font-size:1.8em; color:#00b3e5;\"> Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression( penalty='l2', max_iter=500, C=1, random_state=7 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Arial; font-weight:Bold; font-size:1.5em; color:#00b3e5;\"> Model with BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=500, random_state=7)\n"
     ]
    }
   ],
   "source": [
    "# Fitting\n",
    "BOW_Model = model.fit( CV_Train, Train_Category )\n",
    "print(BOW_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech',\n",
       "       'tech', 'tech', 'politics', 'tech', 'tech', 'entertainment',\n",
       "       'tech', 'tech', 'tech', 'tech', 'sport', 'tech', 'tech', 'tech',\n",
       "       'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech',\n",
       "       'tech', 'tech', 'business', 'tech', 'tech', 'tech', 'tech', 'tech',\n",
       "       'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'politics', 'tech',\n",
       "       'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech',\n",
       "       'tech', 'tech', 'tech', 'politics', 'tech', 'tech', 'tech', 'tech',\n",
       "       'tech', 'tech', 'tech', 'business', 'tech', 'tech', 'tech', 'tech',\n",
       "       'tech', 'politics', 'tech', 'entertainment', 'tech', 'tech',\n",
       "       'tech', 'tech', 'tech', 'tech', 'tech', 'sport', 'tech', 'tech',\n",
       "       'tech', 'entertainment', 'tech', 'tech', 'tech', 'tech', 'tech',\n",
       "       'tech', 'tech', 'tech', 'entertainment', 'tech', 'tech', 'tech',\n",
       "       'tech', 'tech', 'tech', 'tech', 'business', 'tech', 'tech', 'tech',\n",
       "       'tech', 'tech', 'tech', 'sport', 'tech', 'tech', 'tech', 'tech',\n",
       "       'tech', 'tech', 'tech', 'tech', 'politics', 'tech', 'tech', 'tech',\n",
       "       'tech', 'tech', 'tech', 'tech', 'entertainment', 'tech', 'tech',\n",
       "       'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech',\n",
       "       'tech', 'tech', 'tech', 'sport', 'tech', 'tech', 'tech', 'tech',\n",
       "       'tech', 'tech', 'sport', 'tech', 'tech', 'tech', 'tech', 'tech',\n",
       "       'tech', 'tech', 'tech', 'tech', 'politics', 'politics', 'tech',\n",
       "       'sport', 'tech', 'business', 'tech', 'tech', 'tech', 'tech',\n",
       "       'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech',\n",
       "       'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech',\n",
       "       'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech',\n",
       "       'tech', 'tech', 'tech', 'business', 'tech', 'tech', 'tech', 'tech',\n",
       "       'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech',\n",
       "       'politics', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech',\n",
       "       'tech', 'sport', 'tech', 'tech', 'tech', 'tech', 'business'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting\n",
    "BOW_Pred = BOW_Model.predict( CV_Valid )\n",
    "BOW_Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW_Score : 0.25675675675675674\n"
     ]
    }
   ],
   "source": [
    "# Scoring (Accuracy)  \n",
    "BOW_Score = accuracy_score( BOW_Pred, Valid_Category )\n",
    "print(\"BOW_Score :\",BOW_Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Arial; font-weight:Bold; font-size:1.5em; color:#00b3e5;\"> Model with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=500, random_state=7)\n"
     ]
    }
   ],
   "source": [
    "# Fitting\n",
    "TF_Model = model.fit( TF_Train, Train_Category )\n",
    "print(TF_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sport', 'sport', 'sport', 'sport', 'sport', 'tech', 'business',\n",
       "       'sport', 'business', 'business', 'politics', 'sport', 'business',\n",
       "       'entertainment', 'sport', 'sport', 'business', 'business', 'sport',\n",
       "       'sport', 'tech', 'business', 'sport', 'sport', 'business',\n",
       "       'business', 'sport', 'sport', 'sport', 'business', 'business',\n",
       "       'business', 'business', 'business', 'sport', 'business',\n",
       "       'business', 'business', 'business', 'sport', 'sport', 'sport',\n",
       "       'sport', 'business', 'politics', 'sport', 'sport', 'business',\n",
       "       'tech', 'business', 'tech', 'sport', 'business', 'business',\n",
       "       'business', 'sport', 'sport', 'politics', 'business', 'sport',\n",
       "       'sport', 'sport', 'business', 'sport', 'business', 'business',\n",
       "       'tech', 'politics', 'business', 'sport', 'sport', 'politics',\n",
       "       'sport', 'entertainment', 'business', 'sport', 'sport', 'business',\n",
       "       'sport', 'sport', 'sport', 'sport', 'sport', 'entertainment',\n",
       "       'tech', 'entertainment', 'tech', 'sport', 'sport', 'sport',\n",
       "       'sport', 'sport', 'entertainment', 'business', 'entertainment',\n",
       "       'business', 'sport', 'business', 'sport', 'tech', 'tech',\n",
       "       'business', 'business', 'business', 'sport', 'sport', 'sport',\n",
       "       'sport', 'sport', 'sport', 'sport', 'business', 'sport',\n",
       "       'business', 'tech', 'business', 'business', 'sport', 'politics',\n",
       "       'sport', 'sport', 'sport', 'business', 'business', 'sport',\n",
       "       'sport', 'entertainment', 'business', 'sport', 'sport', 'sport',\n",
       "       'sport', 'sport', 'sport', 'sport', 'business', 'sport',\n",
       "       'business', 'business', 'sport', 'sport', 'sport', 'business',\n",
       "       'business', 'sport', 'business', 'business', 'sport', 'business',\n",
       "       'entertainment', 'business', 'sport', 'sport', 'sport', 'tech',\n",
       "       'politics', 'tech', 'politics', 'politics', 'sport', 'sport',\n",
       "       'sport', 'business', 'business', 'sport', 'business', 'sport',\n",
       "       'business', 'sport', 'business', 'sport', 'business', 'business',\n",
       "       'business', 'business', 'sport', 'sport', 'sport', 'business',\n",
       "       'business', 'sport', 'business', 'business', 'business', 'sport',\n",
       "       'sport', 'sport', 'tech', 'business', 'sport', 'sport', 'sport',\n",
       "       'business', 'business', 'business', 'business', 'business',\n",
       "       'politics', 'business', 'business', 'tech', 'business', 'sport',\n",
       "       'sport', 'sport', 'politics', 'business', 'politics', 'sport',\n",
       "       'sport', 'politics', 'business', 'tech', 'business', 'sport',\n",
       "       'sport', 'sport', 'sport', 'business', 'sport', 'business',\n",
       "       'business'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting\n",
    "TF_Pred = TF_Model.predict( TF_Valid )\n",
    "TF_Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF_Score : 0.6531531531531531\n"
     ]
    }
   ],
   "source": [
    "# Scoring (Accuracy)  \n",
    "TF_Score = accuracy_score( TF_Pred, Valid_Category )\n",
    "print(\"TF_Score :\",TF_Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
